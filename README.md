**Responses to GAN Tutorial Questions**
1. Normalization of the images is done in order to prevent biases in the training process. Putting the values between [-1, 1] keeps the range of values small, which prevents bigger values from dominating.
What is the meaning of the BUFFER_SIZE and BATCH_SIZE variables?
2. BUFFER_SIZE refers to the amount of images in the whole dataset, and BATCH_SIZE refers to the size of individual buckets of data generated at any time that will be trained by the model.
3. The generator starts with a 100-dimensional random noise vector, which a Dense layer transforms into a (7, 7, 256) shaped tensor. This tensor gets passed into a few Conv2DTranspose layers, which increase the size of the images and also reduce the number of channels/features. Leaky ReLU allows a small portion of negative neurons in, which helps the generator to keep learning. Batch normalization is used to reset activation layers, which keeps the values of the model consistent. Stride is used when dealing with how many pixels to read when looking at an image. For example, a stride of (2, 2) means the model will read 2 pixels at a time. This works more or less like a zoom/stretch for the images used on the layer.
4. The dropout layer in the discriminator model is used to force the model to identify patterns in the image itself instead of patterns generated from the original data (overfitting). The discriminator processes an image (real or fake) by extracting features layer by layer. Initially, convolutional layers identify simple patterns like edges, while deeper layers capture more complex features. The image is gradually transformed into a 1D vector, which represents all the key information the model has learned from the image.
This 1D vector is passed to a final layer that outputs a single value between 0 and 1, indicating whether the image is real (closer to 1) or fake (closer to 0). During training, the modelâ€™s output is compared to the true labels (1 for real, 0 for fake), and this comparison helps the model improve over time.
5. Binary cross entropy is the measure of how good a model is doing when trying to classify two different things. In this case a value of 1 is given for real images and a value of 0 is given to fake ones. For typcial classification models you usually want the binary cross entropy to be pretty low as in the values are not far of the peaks ( 0.01 and 0.99 being better results than 0.05 and 0.95). Having these values closer to the peaks usually means that the model is more confident in its classifications. This is actually not the case for GANs. The ultimate goal of GAN models is to get the binary cross entropy to about .5 since that shows that the generated image is so close to the real thing that the model cannot confidently discern whether its real or fake.
6. The loss in a GAN is calculated by summing the binary cross-entropy for both real and fake images. Gradient descent uses the calculated loss to adjust the weights of the generator and discriminator. For the discriminator, gradient descent helps it learn to better distinguish real from fake images by minimizing its loss. For the generator, gradient descent adjusts the weights so that the fake images it produces look more like real images over time. Each epoch, these small adjustments help both models improve in their tasks.
7. GANs are a type of model that generate new content by having a generator create fake images and a discriminator distinguish between the real and fake images. As the generator improves, it creates more realistic images, making it harder for the discriminator to identify fakes. This competition pushes both models to get better, with the generator producing increasingly convincing content and the discriminator becoming more adept at distinguishing real from fake.
